---
#
# YAML configuration file for train.py
#

# the random seed, for reproducibility
# if null, no random seed
seed: 42
# the size of each batch of images when training
# careful not to use a too large batch size, might lead to OOM errors
batch_size: 10 # 32
# the number of epochs to train for
epochs: 90
# the learning rate
lr: 0.001
# the path to the root directory of the dataset
dataset_folder: 'D:/Documents/Projets/Github/ChallengeData/ChallengeDataPreligens2021Data/additional_files_earthcube_emu4zqr/dataset'
# the path to the root directory used to store experiments
# a directory per experiment will be created named with the datetime during execution
xp_rootdir: 'D:/Documents/Projets/Github/ChallengeData/ChallengeDataPreligens2021Data/Benchmark'
# CSV file containing the samples to use in the validation set
# if null, a random train/val split is performed, with 10% of the samples held out for validation
# the validation samples will be saved to a file 'val_samples.csv' in the experiment directory
val_samples_csv: null